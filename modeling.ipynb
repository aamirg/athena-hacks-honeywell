{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning\n",
    "\n",
    "Supervised learning is the machine learning task of inferring a function from labeled training data. The training data consist of a set of training examples. Each example is a pair consisting of an input object (typically a vector) and a desired output value. A supervised learning algorithm analyzes the training data and produces an inferred function, which can be used for mapping new examples. \n",
    "\n",
    "- **Classification** - Identifying to which category an object belongs to. \n",
    "- **Regression** - Predicting a continuous-valued attribute associated with an object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the data\n",
    "\n",
    "This dataset contains 13910 measurements from 16 chemical sensors utilized in simulations for drift compensation in a discrimination task of 6 gases at various levels of concentrations.\n",
    "The dataset comprises recordings from six distinct pure gaseous substances, namely Ammonia, Acetaldehyde, Acetone, Ethylene, Ethanol, and Toluene, each dosed at a wide variety of concentration values ranging from 5 to 1000 ppmv.\n",
    "\n",
    "#### Read the csv data into a Pandas dataframe and print the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sensor_A1</th>\n",
       "      <th>Sensor_A2</th>\n",
       "      <th>Sensor_A3</th>\n",
       "      <th>Sensor_A4</th>\n",
       "      <th>Sensor_A5</th>\n",
       "      <th>Sensor_A6</th>\n",
       "      <th>Sensor_A7</th>\n",
       "      <th>Sensor_A8</th>\n",
       "      <th>Sensor_B1</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor_O8</th>\n",
       "      <th>Sensor_P1</th>\n",
       "      <th>Sensor_P2</th>\n",
       "      <th>Sensor_P3</th>\n",
       "      <th>Sensor_P4</th>\n",
       "      <th>Sensor_P5</th>\n",
       "      <th>Sensor_P6</th>\n",
       "      <th>Sensor_P7</th>\n",
       "      <th>Sensor_P8</th>\n",
       "      <th>Batch_No</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15596.1621</td>\n",
       "      <td>1.868245</td>\n",
       "      <td>2.371604</td>\n",
       "      <td>2.803678</td>\n",
       "      <td>7.512213</td>\n",
       "      <td>-2.739388</td>\n",
       "      <td>-3.344671</td>\n",
       "      <td>-4.847512</td>\n",
       "      <td>15326.6914</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.037772</td>\n",
       "      <td>3037.0390</td>\n",
       "      <td>3.972203</td>\n",
       "      <td>0.527291</td>\n",
       "      <td>0.728443</td>\n",
       "      <td>1.445783</td>\n",
       "      <td>-0.545079</td>\n",
       "      <td>-0.902241</td>\n",
       "      <td>-2.654529</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>26402.0704</td>\n",
       "      <td>2.532401</td>\n",
       "      <td>5.411209</td>\n",
       "      <td>6.509906</td>\n",
       "      <td>7.658469</td>\n",
       "      <td>-4.722217</td>\n",
       "      <td>-5.817651</td>\n",
       "      <td>-7.518333</td>\n",
       "      <td>23855.7812</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.994993</td>\n",
       "      <td>4176.4453</td>\n",
       "      <td>4.281373</td>\n",
       "      <td>0.980205</td>\n",
       "      <td>1.628050</td>\n",
       "      <td>1.951172</td>\n",
       "      <td>-0.889333</td>\n",
       "      <td>-1.323505</td>\n",
       "      <td>-1.749225</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>42103.5820</td>\n",
       "      <td>3.454189</td>\n",
       "      <td>8.198175</td>\n",
       "      <td>10.508439</td>\n",
       "      <td>11.611003</td>\n",
       "      <td>-7.668313</td>\n",
       "      <td>-9.478675</td>\n",
       "      <td>-12.230939</td>\n",
       "      <td>37562.3008</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.867291</td>\n",
       "      <td>5914.6685</td>\n",
       "      <td>5.396827</td>\n",
       "      <td>1.403973</td>\n",
       "      <td>2.476956</td>\n",
       "      <td>3.039841</td>\n",
       "      <td>-1.334558</td>\n",
       "      <td>-1.993659</td>\n",
       "      <td>-2.348370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>42825.9883</td>\n",
       "      <td>3.451192</td>\n",
       "      <td>12.113940</td>\n",
       "      <td>16.266853</td>\n",
       "      <td>39.910056</td>\n",
       "      <td>-7.849409</td>\n",
       "      <td>-9.689894</td>\n",
       "      <td>-11.921704</td>\n",
       "      <td>38379.0664</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.058086</td>\n",
       "      <td>6147.4744</td>\n",
       "      <td>5.501071</td>\n",
       "      <td>1.981933</td>\n",
       "      <td>3.569823</td>\n",
       "      <td>4.049197</td>\n",
       "      <td>-1.432205</td>\n",
       "      <td>-2.146158</td>\n",
       "      <td>-2.488957</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>58151.1757</td>\n",
       "      <td>4.194839</td>\n",
       "      <td>11.455096</td>\n",
       "      <td>15.715298</td>\n",
       "      <td>17.654915</td>\n",
       "      <td>-11.083364</td>\n",
       "      <td>-13.580692</td>\n",
       "      <td>-16.407848</td>\n",
       "      <td>51975.5899</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.181920</td>\n",
       "      <td>8158.6449</td>\n",
       "      <td>7.174334</td>\n",
       "      <td>1.993808</td>\n",
       "      <td>3.829303</td>\n",
       "      <td>4.402448</td>\n",
       "      <td>-1.930107</td>\n",
       "      <td>-2.931265</td>\n",
       "      <td>-4.088756</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label   Sensor_A1  Sensor_A2  Sensor_A3  Sensor_A4  Sensor_A5  Sensor_A6  \\\n",
       "0      1  15596.1621   1.868245   2.371604   2.803678   7.512213  -2.739388   \n",
       "1      1  26402.0704   2.532401   5.411209   6.509906   7.658469  -4.722217   \n",
       "2      1  42103.5820   3.454189   8.198175  10.508439  11.611003  -7.668313   \n",
       "3      1  42825.9883   3.451192  12.113940  16.266853  39.910056  -7.849409   \n",
       "4      1  58151.1757   4.194839  11.455096  15.715298  17.654915 -11.083364   \n",
       "\n",
       "   Sensor_A7  Sensor_A8   Sensor_B1    ...     Sensor_O8  Sensor_P1  \\\n",
       "0  -3.344671  -4.847512  15326.6914    ...     -3.037772  3037.0390   \n",
       "1  -5.817651  -7.518333  23855.7812    ...     -1.994993  4176.4453   \n",
       "2  -9.478675 -12.230939  37562.3008    ...     -2.867291  5914.6685   \n",
       "3  -9.689894 -11.921704  38379.0664    ...     -3.058086  6147.4744   \n",
       "4 -13.580692 -16.407848  51975.5899    ...     -4.181920  8158.6449   \n",
       "\n",
       "   Sensor_P2  Sensor_P3  Sensor_P4  Sensor_P5  Sensor_P6  Sensor_P7  \\\n",
       "0   3.972203   0.527291   0.728443   1.445783  -0.545079  -0.902241   \n",
       "1   4.281373   0.980205   1.628050   1.951172  -0.889333  -1.323505   \n",
       "2   5.396827   1.403973   2.476956   3.039841  -1.334558  -1.993659   \n",
       "3   5.501071   1.981933   3.569823   4.049197  -1.432205  -2.146158   \n",
       "4   7.174334   1.993808   3.829303   4.402448  -1.930107  -2.931265   \n",
       "\n",
       "   Sensor_P8  Batch_No  \n",
       "0  -2.654529         1  \n",
       "1  -1.749225         1  \n",
       "2  -2.348370         1  \n",
       "3  -2.488957         1  \n",
       "4  -4.088756         1  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./formatted_data.csv\",header=0, index_col=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each sensor the second column is the normalized form of the first column, so to avoid duplicates we drop the first column (A1,B1...P1) for each sensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sensor_A2</th>\n",
       "      <th>Sensor_A3</th>\n",
       "      <th>Sensor_A4</th>\n",
       "      <th>Sensor_A5</th>\n",
       "      <th>Sensor_A6</th>\n",
       "      <th>Sensor_A7</th>\n",
       "      <th>Sensor_A8</th>\n",
       "      <th>Sensor_B2</th>\n",
       "      <th>Sensor_B3</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor_O6</th>\n",
       "      <th>Sensor_O7</th>\n",
       "      <th>Sensor_O8</th>\n",
       "      <th>Sensor_P2</th>\n",
       "      <th>Sensor_P3</th>\n",
       "      <th>Sensor_P4</th>\n",
       "      <th>Sensor_P5</th>\n",
       "      <th>Sensor_P6</th>\n",
       "      <th>Sensor_P7</th>\n",
       "      <th>Sensor_P8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.868245</td>\n",
       "      <td>2.371604</td>\n",
       "      <td>2.803678</td>\n",
       "      <td>7.512213</td>\n",
       "      <td>-2.739388</td>\n",
       "      <td>-3.344671</td>\n",
       "      <td>-4.847512</td>\n",
       "      <td>1.768526</td>\n",
       "      <td>2.269085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.619214</td>\n",
       "      <td>-1.071137</td>\n",
       "      <td>-3.037772</td>\n",
       "      <td>3.972203</td>\n",
       "      <td>0.527291</td>\n",
       "      <td>0.728443</td>\n",
       "      <td>1.445783</td>\n",
       "      <td>-0.545079</td>\n",
       "      <td>-0.902241</td>\n",
       "      <td>-2.654529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.532401</td>\n",
       "      <td>5.411209</td>\n",
       "      <td>6.509906</td>\n",
       "      <td>7.658469</td>\n",
       "      <td>-4.722217</td>\n",
       "      <td>-5.817651</td>\n",
       "      <td>-7.518333</td>\n",
       "      <td>2.164706</td>\n",
       "      <td>4.901063</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.004812</td>\n",
       "      <td>-1.530519</td>\n",
       "      <td>-1.994993</td>\n",
       "      <td>4.281373</td>\n",
       "      <td>0.980205</td>\n",
       "      <td>1.628050</td>\n",
       "      <td>1.951172</td>\n",
       "      <td>-0.889333</td>\n",
       "      <td>-1.323505</td>\n",
       "      <td>-1.749225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3.454189</td>\n",
       "      <td>8.198175</td>\n",
       "      <td>10.508439</td>\n",
       "      <td>11.611003</td>\n",
       "      <td>-7.668313</td>\n",
       "      <td>-9.478675</td>\n",
       "      <td>-12.230939</td>\n",
       "      <td>2.840403</td>\n",
       "      <td>7.386357</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.518135</td>\n",
       "      <td>-2.384784</td>\n",
       "      <td>-2.867291</td>\n",
       "      <td>5.396827</td>\n",
       "      <td>1.403973</td>\n",
       "      <td>2.476956</td>\n",
       "      <td>3.039841</td>\n",
       "      <td>-1.334558</td>\n",
       "      <td>-1.993659</td>\n",
       "      <td>-2.348370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3.451192</td>\n",
       "      <td>12.113940</td>\n",
       "      <td>16.266853</td>\n",
       "      <td>39.910056</td>\n",
       "      <td>-7.849409</td>\n",
       "      <td>-9.689894</td>\n",
       "      <td>-11.921704</td>\n",
       "      <td>2.851173</td>\n",
       "      <td>10.840889</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.644751</td>\n",
       "      <td>-2.607199</td>\n",
       "      <td>-3.058086</td>\n",
       "      <td>5.501071</td>\n",
       "      <td>1.981933</td>\n",
       "      <td>3.569823</td>\n",
       "      <td>4.049197</td>\n",
       "      <td>-1.432205</td>\n",
       "      <td>-2.146158</td>\n",
       "      <td>-2.488957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4.194839</td>\n",
       "      <td>11.455096</td>\n",
       "      <td>15.715298</td>\n",
       "      <td>17.654915</td>\n",
       "      <td>-11.083364</td>\n",
       "      <td>-13.580692</td>\n",
       "      <td>-16.407848</td>\n",
       "      <td>3.480866</td>\n",
       "      <td>10.409176</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.249702</td>\n",
       "      <td>-3.594763</td>\n",
       "      <td>-4.181920</td>\n",
       "      <td>7.174334</td>\n",
       "      <td>1.993808</td>\n",
       "      <td>3.829303</td>\n",
       "      <td>4.402448</td>\n",
       "      <td>-1.930107</td>\n",
       "      <td>-2.931265</td>\n",
       "      <td>-4.088756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Sensor_A2  Sensor_A3  Sensor_A4  Sensor_A5  Sensor_A6  Sensor_A7  \\\n",
       "0      1   1.868245   2.371604   2.803678   7.512213  -2.739388  -3.344671   \n",
       "1      1   2.532401   5.411209   6.509906   7.658469  -4.722217  -5.817651   \n",
       "2      1   3.454189   8.198175  10.508439  11.611003  -7.668313  -9.478675   \n",
       "3      1   3.451192  12.113940  16.266853  39.910056  -7.849409  -9.689894   \n",
       "4      1   4.194839  11.455096  15.715298  17.654915 -11.083364 -13.580692   \n",
       "\n",
       "   Sensor_A8  Sensor_B2  Sensor_B3    ...      Sensor_O6  Sensor_O7  \\\n",
       "0  -4.847512   1.768526   2.269085    ...      -0.619214  -1.071137   \n",
       "1  -7.518333   2.164706   4.901063    ...      -1.004812  -1.530519   \n",
       "2 -12.230939   2.840403   7.386357    ...      -1.518135  -2.384784   \n",
       "3 -11.921704   2.851173  10.840889    ...      -1.644751  -2.607199   \n",
       "4 -16.407848   3.480866  10.409176    ...      -2.249702  -3.594763   \n",
       "\n",
       "   Sensor_O8  Sensor_P2  Sensor_P3  Sensor_P4  Sensor_P5  Sensor_P6  \\\n",
       "0  -3.037772   3.972203   0.527291   0.728443   1.445783  -0.545079   \n",
       "1  -1.994993   4.281373   0.980205   1.628050   1.951172  -0.889333   \n",
       "2  -2.867291   5.396827   1.403973   2.476956   3.039841  -1.334558   \n",
       "3  -3.058086   5.501071   1.981933   3.569823   4.049197  -1.432205   \n",
       "4  -4.181920   7.174334   1.993808   3.829303   4.402448  -1.930107   \n",
       "\n",
       "   Sensor_P7  Sensor_P8  \n",
       "0  -0.902241  -2.654529  \n",
       "1  -1.323505  -1.749225  \n",
       "2  -1.993659  -2.348370  \n",
       "3  -2.146158  -2.488957  \n",
       "4  -2.931265  -4.088756  \n",
       "\n",
       "[5 rows x 113 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols = ['Sensor_'+x+'1' for x in map(chr,range(65,81))]\n",
    "drop_cols.append('Batch_No')\n",
    "data = data.drop(drop_cols, axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize the data to better understand its distribution and decide on the appropriate preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sensor_A2</th>\n",
       "      <th>Sensor_A3</th>\n",
       "      <th>Sensor_A4</th>\n",
       "      <th>Sensor_A5</th>\n",
       "      <th>Sensor_A6</th>\n",
       "      <th>Sensor_A7</th>\n",
       "      <th>Sensor_A8</th>\n",
       "      <th>Sensor_B2</th>\n",
       "      <th>Sensor_B3</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor_O6</th>\n",
       "      <th>Sensor_O7</th>\n",
       "      <th>Sensor_O8</th>\n",
       "      <th>Sensor_P2</th>\n",
       "      <th>Sensor_P3</th>\n",
       "      <th>Sensor_P4</th>\n",
       "      <th>Sensor_P5</th>\n",
       "      <th>Sensor_P6</th>\n",
       "      <th>Sensor_P7</th>\n",
       "      <th>Sensor_P8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13910.000000</td>\n",
       "      <td>13910.000000</td>\n",
       "      <td>13910.000000</td>\n",
       "      <td>13910.000000</td>\n",
       "      <td>13910.000000</td>\n",
       "      <td>13910.000000</td>\n",
       "      <td>13910.000000</td>\n",
       "      <td>13910.000000</td>\n",
       "      <td>13910.000000</td>\n",
       "      <td>13910.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13910.000000</td>\n",
       "      <td>13910.000000</td>\n",
       "      <td>13910.000000</td>\n",
       "      <td>13910.000000</td>\n",
       "      <td>13910.000000</td>\n",
       "      <td>13910.000000</td>\n",
       "      <td>13910.000000</td>\n",
       "      <td>13910.000000</td>\n",
       "      <td>13910.000000</td>\n",
       "      <td>13910.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.387994</td>\n",
       "      <td>6.638156</td>\n",
       "      <td>12.936688</td>\n",
       "      <td>18.743953</td>\n",
       "      <td>26.890695</td>\n",
       "      <td>-9.158655</td>\n",
       "      <td>-14.402383</td>\n",
       "      <td>-59.927598</td>\n",
       "      <td>6.648033</td>\n",
       "      <td>15.538389</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.664942</td>\n",
       "      <td>-9.601927</td>\n",
       "      <td>-19.136500</td>\n",
       "      <td>6.072066</td>\n",
       "      <td>7.138634</td>\n",
       "      <td>14.929364</td>\n",
       "      <td>19.090980</td>\n",
       "      <td>-4.901016</td>\n",
       "      <td>-8.167792</td>\n",
       "      <td>-16.089791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.728602</td>\n",
       "      <td>13.486391</td>\n",
       "      <td>17.610061</td>\n",
       "      <td>24.899450</td>\n",
       "      <td>38.107685</td>\n",
       "      <td>12.729206</td>\n",
       "      <td>21.304606</td>\n",
       "      <td>131.017675</td>\n",
       "      <td>15.585780</td>\n",
       "      <td>16.557172</td>\n",
       "      <td>...</td>\n",
       "      <td>4.996011</td>\n",
       "      <td>9.220031</td>\n",
       "      <td>26.516679</td>\n",
       "      <td>4.642192</td>\n",
       "      <td>5.248573</td>\n",
       "      <td>12.437311</td>\n",
       "      <td>14.391810</td>\n",
       "      <td>4.195360</td>\n",
       "      <td>7.637701</td>\n",
       "      <td>20.958479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.088287</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>-131.332873</td>\n",
       "      <td>-227.627758</td>\n",
       "      <td>-1664.735576</td>\n",
       "      <td>0.185164</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>...</td>\n",
       "      <td>-36.163600</td>\n",
       "      <td>-76.069200</td>\n",
       "      <td>-482.278033</td>\n",
       "      <td>0.712112</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>0.011488</td>\n",
       "      <td>0.118849</td>\n",
       "      <td>-30.205911</td>\n",
       "      <td>-58.844076</td>\n",
       "      <td>-410.152297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.284843</td>\n",
       "      <td>1.633350</td>\n",
       "      <td>2.386836</td>\n",
       "      <td>4.967988</td>\n",
       "      <td>-11.587169</td>\n",
       "      <td>-17.292559</td>\n",
       "      <td>-48.492764</td>\n",
       "      <td>2.776693</td>\n",
       "      <td>3.700962</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.930521</td>\n",
       "      <td>-13.212575</td>\n",
       "      <td>-22.363498</td>\n",
       "      <td>3.007380</td>\n",
       "      <td>3.059178</td>\n",
       "      <td>5.407551</td>\n",
       "      <td>8.039227</td>\n",
       "      <td>-6.789599</td>\n",
       "      <td>-11.162406</td>\n",
       "      <td>-18.938690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.871227</td>\n",
       "      <td>4.977123</td>\n",
       "      <td>7.250892</td>\n",
       "      <td>11.680725</td>\n",
       "      <td>-3.338700</td>\n",
       "      <td>-4.956917</td>\n",
       "      <td>-14.040088</td>\n",
       "      <td>4.734586</td>\n",
       "      <td>9.968119</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.469910</td>\n",
       "      <td>-7.338850</td>\n",
       "      <td>-13.527887</td>\n",
       "      <td>4.973783</td>\n",
       "      <td>5.809107</td>\n",
       "      <td>11.325215</td>\n",
       "      <td>14.560676</td>\n",
       "      <td>-3.881763</td>\n",
       "      <td>-6.305962</td>\n",
       "      <td>-11.747499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.400619</td>\n",
       "      <td>17.189165</td>\n",
       "      <td>26.411109</td>\n",
       "      <td>34.843226</td>\n",
       "      <td>-1.126897</td>\n",
       "      <td>-1.670327</td>\n",
       "      <td>-5.212213</td>\n",
       "      <td>8.608522</td>\n",
       "      <td>20.383726</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.043721</td>\n",
       "      <td>-3.260080</td>\n",
       "      <td>-7.358031</td>\n",
       "      <td>7.389566</td>\n",
       "      <td>10.222169</td>\n",
       "      <td>21.207572</td>\n",
       "      <td>26.547437</td>\n",
       "      <td>-1.804032</td>\n",
       "      <td>-2.874532</td>\n",
       "      <td>-6.429690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>1339.879283</td>\n",
       "      <td>167.079751</td>\n",
       "      <td>226.619457</td>\n",
       "      <td>993.605306</td>\n",
       "      <td>-0.006941</td>\n",
       "      <td>22.201589</td>\n",
       "      <td>115.273147</td>\n",
       "      <td>1672.363221</td>\n",
       "      <td>131.449632</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009767</td>\n",
       "      <td>9.270956</td>\n",
       "      <td>11.516418</td>\n",
       "      <td>45.574835</td>\n",
       "      <td>32.203601</td>\n",
       "      <td>297.225880</td>\n",
       "      <td>195.242555</td>\n",
       "      <td>-0.003817</td>\n",
       "      <td>6.851792</td>\n",
       "      <td>8.357968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Label     Sensor_A2     Sensor_A3     Sensor_A4     Sensor_A5  \\\n",
       "count  13910.000000  13910.000000  13910.000000  13910.000000  13910.000000   \n",
       "mean       3.387994      6.638156     12.936688     18.743953     26.890695   \n",
       "std        1.728602     13.486391     17.610061     24.899450     38.107685   \n",
       "min        1.000000      0.088287      0.000100      0.000100      0.000100   \n",
       "25%        2.000000      2.284843      1.633350      2.386836      4.967988   \n",
       "50%        3.000000      3.871227      4.977123      7.250892     11.680725   \n",
       "75%        5.000000      8.400619     17.189165     26.411109     34.843226   \n",
       "max        6.000000   1339.879283    167.079751    226.619457    993.605306   \n",
       "\n",
       "          Sensor_A6     Sensor_A7     Sensor_A8     Sensor_B2     Sensor_B3  \\\n",
       "count  13910.000000  13910.000000  13910.000000  13910.000000  13910.000000   \n",
       "mean      -9.158655    -14.402383    -59.927598      6.648033     15.538389   \n",
       "std       12.729206     21.304606    131.017675     15.585780     16.557172   \n",
       "min     -131.332873   -227.627758  -1664.735576      0.185164      0.002252   \n",
       "25%      -11.587169    -17.292559    -48.492764      2.776693      3.700962   \n",
       "50%       -3.338700     -4.956917    -14.040088      4.734586      9.968119   \n",
       "75%       -1.126897     -1.670327     -5.212213      8.608522     20.383726   \n",
       "max       -0.006941     22.201589    115.273147   1672.363221    131.449632   \n",
       "\n",
       "           ...          Sensor_O6     Sensor_O7     Sensor_O8     Sensor_P2  \\\n",
       "count      ...       13910.000000  13910.000000  13910.000000  13910.000000   \n",
       "mean       ...          -5.664942     -9.601927    -19.136500      6.072066   \n",
       "std        ...           4.996011      9.220031     26.516679      4.642192   \n",
       "min        ...         -36.163600    -76.069200   -482.278033      0.712112   \n",
       "25%        ...          -7.930521    -13.212575    -22.363498      3.007380   \n",
       "50%        ...          -4.469910     -7.338850    -13.527887      4.973783   \n",
       "75%        ...          -2.043721     -3.260080     -7.358031      7.389566   \n",
       "max        ...          -0.009767      9.270956     11.516418     45.574835   \n",
       "\n",
       "          Sensor_P3     Sensor_P4     Sensor_P5     Sensor_P6     Sensor_P7  \\\n",
       "count  13910.000000  13910.000000  13910.000000  13910.000000  13910.000000   \n",
       "mean       7.138634     14.929364     19.090980     -4.901016     -8.167792   \n",
       "std        5.248573     12.437311     14.391810      4.195360      7.637701   \n",
       "min        0.003238      0.011488      0.118849    -30.205911    -58.844076   \n",
       "25%        3.059178      5.407551      8.039227     -6.789599    -11.162406   \n",
       "50%        5.809107     11.325215     14.560676     -3.881763     -6.305962   \n",
       "75%       10.222169     21.207572     26.547437     -1.804032     -2.874532   \n",
       "max       32.203601    297.225880    195.242555     -0.003817      6.851792   \n",
       "\n",
       "          Sensor_P8  \n",
       "count  13910.000000  \n",
       "mean     -16.089791  \n",
       "std       20.958479  \n",
       "min     -410.152297  \n",
       "25%      -18.938690  \n",
       "50%      -11.747499  \n",
       "75%       -6.429690  \n",
       "max        8.357968  \n",
       "\n",
       "[8 rows x 113 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing \n",
    "1. **Dealing with missing values** - Real world datasets often contain missing values, represented by blanks, NaNs etc\n",
    "  1. Discard rows and/or columns containing missing values at the risk of losing valuable data\n",
    "  2. Impute missing values by replacing them with the mean value of the column. An advanced way is to build a regression model to impute the missing values\n",
    "  \n",
    "2. **Encoding categorical features** - Using a label encoder helps us transform non-numerical labels to numerical labels. Another approach is Dummy encoding where you convert an attribute by creating duplicate variables which represents one level of a categorical variable. Presence of a level is represent by 1 and absence is represented by 0. For every level present, one dummy variable will be created. <br> In this dataset our target labels are categorical values that have already been encoded as numerical <br>\n",
    "[1: Ethanol; 2: Ethylene; 3:Ammonia; 4: Acetaldehyde; 5: Acetone; 6: Toluene]\n",
    "3. **Feature scaling** - We standardize the features to ensure that just because some features have a larger magnitude our model won't lead us to using them as the main predictor. Feature scaling helps reduces the training time for models and avoids the optimization from getting stuck in local optima.\n",
    " 1. Min-Max Scaling - Involves rescaling the range of features to scale the range in [0, 1] or [−1, 1]. Selecting the target range depends on the nature of the data.\n",
    " 2. Standardizing a dataset involves rescaling the distribution of values so that the mean of observed values is 0 and the standard deviation is 1.\n",
    " 3. Scaling to unit length - the vector magnitude is used to obtain a vector of unit length. This usually means dividing each component by the [Euclidean length of the vector](https://help.github.com/articles/basic-writing-and-formatting-syntax/#links)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate the data into input and output components and perform feature scaling on the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "target = data['Label']\n",
    "data = data.drop('Label', axis=1)\n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(-1,1))\n",
    "data_scaled = min_max_scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into a training set and test set. \n",
    "\n",
    "If we use the entire dataset to train our model, it will end up modeling random error/noise present in the data, and will have poor predictive performance on unseen future data.  This situation is known as **Overfitting**. To avoid this we hold out part of the available data as a test set and use the remaining for training. Some common splits are 90/10, 80/20, 75/25. \n",
    "\n",
    "There is a risk of overfitting on the test set as you try to optimize the hyperparameters of parametric models to achieve optimal performance.  To solve this problem, yet another part of the dataset can be held out as a so-called “validation set”. Thus training is carried out on the training set, evaluation is done on the validation set and once the parameters have been tuned, final evaluation is carried out on the \"unseen\" test set. \n",
    "\n",
    "The drawback of this approach is that we drastically reduce the number of samples which can be used for learning the model, and the results can depend on a particular random choice for the pair of (train, validation) sets. To solve this we use a procedure called **Cross-validation** which is discussed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_scaled, target, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial v/s Multinomial classification \n",
    "\n",
    "**Binomial** classification problem is one where the dataset has 2 target classes in the dataset. We are dealing with a **Multinomial** classification problem, as we have more than 2 target classes in our dataset. To leverage binary classifiers for multinomial classification we can use one of the following strategies-\n",
    "1. One-vs-All : It involves training a single classifier per class, with the samples of that class as positive samples and all other samples as negatives.\n",
    "\n",
    "2. One-vs-One : It involves training K(K-1)/2 binary classifiers for a K-multiclass problem; each receives the samples of a pair of classes from the original training set, and must learn to distinguish these two classes. At prediction time, a voting scheme is applied: all K (K − 1) / 2 classifiers are applied to an unseen sample and the class that got the highest number of \"+1\" predictions gets predicted by the combined classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a model\n",
    "\n",
    "#### Decision Tree - \n",
    "Decision Trees are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable based on several input variables. It is a flow-chart-like structure, where each internal (non-leaf) node denotes a test on an attribute, each branch represents the outcome of a test, and each leaf (or terminal) node holds a class label. The topmost node in a tree is the root node.\n",
    "\n",
    "Non-parametric models (can) become more and more complex with an increasing amount of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "dt_classifier = tree.DecisionTreeClassifier()\n",
    "dt_classifier = dt_classifier.fit(X_train, y_train)\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "print \"Accuracy: %0.2f\" %dt_classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code snippet we fit a decision tree to our dataset, used it to make predictions on our test set and we calculated its accuracy as the number of correct predictions from all predictions made. Accuracy is a starting point but is not a sufficient measure for evaluating a model's predictive power due to a phenomena known as [**Accuracy Paradox**](https://tryolabs.com/blog/2013/03/25/why-accuracy-alone-bad-measure-classification-tasks-and-what-we-can-do-about-it/). It yields misleading results if the data set is unbalanced.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation metrics\n",
    "\n",
    "A clean and unambiguous way to visualize the performance of a classifier is to use a use a **Confusion matrix**\n",
    "\n",
    "                          \n",
    "\n",
    "|                                 | *Predicted class - Positive* | *Predicted class - Negative* |\n",
    "|---------------------------------|----------------------------------|                                  |\n",
    "|**_Acutal class - Positive_**  |  True Positive  (TP)             |   False negative  (FN)           |\n",
    "|**_Acutal class - Negative_**  |  False Positive (FP)             |   True negative   (TN)           |\n",
    "\n",
    "- True Positives (TP): number of positive examples, labeled as such.\n",
    "- False Positives (FP): number of negative examples, labeled as positive.\n",
    "- True Negatives (TN): number of negative examples, labeled as such.\n",
    "- False Negatives (FN): number of positive examples, labeled as negative.\n",
    "\n",
    "We use these values to calculate **Precision** and **Recall**-\n",
    "\n",
    "1. Precision answers the following question : out of all the examples the classifier labeled as positive, what fraction were correct. \n",
    " $$Precision = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "2. Recall answers out of all the positive examples there were, what fraction did the classifier pick up. It is calculated as - \n",
    " $$Recall = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "The harmonic mean of Precision and Recall is known as the **F1 Score**. It conveys the balance between the precision and the recall. \n",
    "$$ F_1  score = \\frac{2 \\times Precision \\times Recall}{Precision + Recall}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the confusion matrix for the decision tree. The sci-kit learn method just returns a nested array without any labels, so we plot for easier interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAGbCAYAAAAcMUOXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEDAADAQMAAMBA8BAwAAwEDAADAQMAIMALxz0VKfVEnQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd395898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "   \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    \n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "#plt.figure()\n",
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred), classes=[\"Ethanol\", \"Ethylene\", \"Ammonia\", \"Acetaldehyde\", \"Acetone\", \"Toluene\"],\n",
    "                      title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We use one of the methods to compute Precision, Recall and F-1 score for each class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Ethanol       0.98      0.98      0.98       620\n",
      "    Ethylene       0.99      0.98      0.98       737\n",
      "     Ammonia       0.96      0.97      0.97       400\n",
      "Acetaldehyde       0.95      0.95      0.95       505\n",
      "     Acetone       0.98      0.98      0.98       744\n",
      "     Toluene       0.96      0.97      0.97       472\n",
      "\n",
      " avg / total       0.97      0.97      0.97      3478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pred, target_names=[\"Ethanol\", \"Ethylene\", \"Ammonia\", \"Acetaldehyde\", \"Acetone\", \"Toluene\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation\n",
    "\n",
    "Cross validation is a method for estimating the prediction accuracy of a model on an unseen dataset without using a validation set. Instead of just holding out one part of the data to train on, you hold out different parts. For each part, you train on the rest, and evaluate the set you held out. Now you have effectively used all of your data for testing & training, without testing on data you trained on.\n",
    "\n",
    "The different methods are - \n",
    "\n",
    "1. **k-fold CV** -  The training set is split into k smaller sets and the model is trained using k-1 folds. The resulting model is validated on the remaining part of the data\n",
    "2. **Leave One out** - Each learning set is created by taking all the samples except one, the test set being the sample left out. Thus, for n samples, we have n different training sets and n different tests set. \n",
    "3. **Leave P Out** - Similar to Leave One out as it creates all the possible training/test sets by removing p samples from the complete set. \n",
    "4. **Random Shuffle & Split** - It will generate a user defined number of independent train / test dataset splits. Samples are first shuffled and then split into a pair of train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def cv_score(clf,k):\n",
    "    f1_scores = cross_val_score(clf, data_scaled, target, cv=k, scoring='f1_macro')\n",
    "    print f1_scores\n",
    "    print(\"F1 score: %0.2f (+/- %0.2f)\" % (f1_scores.mean(), f1_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the score computed at each CV iteration is the score method of the estimator. \n",
    "It is possible to change this by using the scoring parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.84 (+/- 0.21)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print cv_score(dt_classifier,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble learning\n",
    "\n",
    "Ensemble methods are a divide-and-conquer approach used to improve performance. The main principle behind ensemble methods is that a group of “weak learners” can come together to form a “strong learner”.Ensemble learning methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone. One such method is Random Forests.\n",
    "\n",
    "#### Random Forests\n",
    "Decision trees are a popular & easy to interpret method but trees that are grown very deep tend to learn highly irregular patterns (noise). They tend to overfit their training sets i.e have low bias but very high variance. \n",
    "\n",
    "Random Forests a way of averaging multiple deep decision trees, trained on different parts of the same training set, with the goal of reducing the variance.This comes at the expense of a small increase in the bias and some loss of interpretability, but generally greatly boosts the performance of the final model as the individual decision trees are less correlated. \n",
    "So how are the trees different? Well,\n",
    "1. We used random samples of the observations to train them (they've each seen only part of the data) , and\n",
    "2. We used a subset of the features for each tree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.89 (+/- 0.17)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=5)\n",
    "#rf_classifier = rf_classifier.fit(X_train, y_train)\n",
    "#y_pred_rf = classifier.predict(X_test)\n",
    "#print \"Accuracy: %0.2f\" %rf_classifier.score(X_test, y_test)\n",
    "print cv_score(rf_classifier,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot_confusion_matrix(confusion_matrix(y_test, y_pred_rf), classes=[\"Ethanol\", \"Ethylene\", \"Ammonia\", \"Acetaldehyde\", \"Acetone\", \"Toluene\"],\n",
    "#                      title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-502bda0e3e17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;32mprint\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_rf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Ethanol\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Ethylene\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Ammonia\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Acetaldehyde\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Acetone\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Toluene\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred_rf' is not defined"
     ]
    }
   ],
   "source": [
    "#print classification_report(y_test, y_pred_rf, target_names=[\"Ethanol\", \"Ethylene\", \"Ammonia\", \"Acetaldehyde\", \"Acetone\", \"Toluene\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias - Variance Trade off\n",
    "\n",
    "The bias–variance tradeoff is the problem of simultaneously minimizing two sources of error that prevent supervised learning algorithms from generalizing beyond their training set. \n",
    "\n",
    "- **Bias** : error from erroneous assumptions in the learning algorithm. High bias can cause underfitting : algorithm misses the relevant relations between features and target outputs.\n",
    "\n",
    "- **Variance** : error from sensitivity to small fluctuations in the training set. High variance can cause overfitting: modeling the random noise in the training data, rather than the intended outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines\n",
    "\n",
    "An SVM model is a representation of the examples as points in space, mapped so that the examples of the separate categories are divided by a clear gap that is as wide as possible. New examples are then mapped into that same space and predicted to belong to a category based on which side of the gap they fall. It is a parametric learner hence we have a finite number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.76 (+/- 0.26)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "svm_classifier = svm.SVC(C=1.0, kernel='rbf' ,gamma='auto', cache_size=9000, decision_function_shape = 'ovr')\n",
    "print cv_score(svm_classifier,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization\n",
    "\n",
    "Hyperparameter optimization is the problem of choosing a set of hyperparameters for a learning algorithm, usually with the goal of optimizing a measure of the algorithm's performance.\n",
    "\n",
    "#### Grid Search \n",
    "\n",
    "Grid search, or a parameter sweep, is simply an exhaustive searching through a manually specified subset of the hyperparameter space of a learning algorithm. A grid search algorithm must be guided by some performance metric, typically measured by cross-validation on the training set or evaluation on a held-out validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "C_range = np.logspace(-2, 10, 5)\n",
    "gamma_range = np.logspace(-9, 3, 5)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "grid = GridSearchCV(svm.SVC(), param_grid=param_grid, cv=cv)\n",
    "\n",
    "grid.fit(data, target)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StratifiedShuffleSplit used above is a variation of ShuffleSplit, which returns stratified splits, i.e which creates splits by preserving the same percentage for each target class as in the complete set."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
